{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c708d919",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprepare_ml_dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrain_nn_model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import prepare_ml_dataset\n",
    "import train_nn_model\n",
    "import importlib\n",
    "import pandas as pd\n",
    "\n",
    "importlib.reload(prepare_ml_dataset)\n",
    "importlib.reload(train_nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f8545a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = '51767680'\n",
    "species = 'h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27dd3816-430f-4e4e-8292-82b72ce08715",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_ml_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m directories, dataset_csv, data_settings \u001b[38;5;241m=\u001b[39m prepare_ml_dataset\u001b[38;5;241m.\u001b[39minitializ_var(energy, species)\n\u001b[1;32m      2\u001b[0m y_name\u001b[38;5;241m=\u001b[39mdata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      3\u001b[0m y_name_log\u001b[38;5;241m=\u001b[39mdata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_name_log\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_ml_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "directories, dataset_csv, data_settings = prepare_ml_dataset.initializ_var(energy, species)\n",
    "y_name=data_settings[\"y_name\"]\n",
    "y_name_log=data_settings[\"y_name_log\"]\n",
    "feature_names=data_settings[\"feature_names\"]\n",
    "dL01=data_settings[\"dL01\"]\n",
    "release=data_settings[\"release\"]\n",
    "data_dir = directories[\"data_dir\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d67e91-f26e-4584-b2e1-943d84df2ca3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_ml_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_full \u001b[38;5;241m=\u001b[39m prepare_ml_dataset\u001b[38;5;241m.\u001b[39mread_csv_data(data_dir, release)      \n\u001b[1;32m      3\u001b[0m index_good \u001b[38;5;241m=\u001b[39m prepare_ml_dataset\u001b[38;5;241m.\u001b[39mcreate_good_index(df_full, y_name , feature_names, dL01)\n\u001b[1;32m      5\u001b[0m df_full \u001b[38;5;241m=\u001b[39m prepare_ml_dataset\u001b[38;5;241m.\u001b[39mcalculate_log_for_y(df_full, y_name , y_name_log , index_good )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_ml_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "df_full = prepare_ml_dataset.read_csv_data(data_dir, release)      \n",
    "\n",
    "index_good = prepare_ml_dataset.create_good_index(df_full, y_name , feature_names, dL01)\n",
    "\n",
    "df_full = prepare_ml_dataset.calculate_log_for_y(df_full, y_name , y_name_log , index_good )\n",
    "\n",
    "df_full = prepare_ml_dataset.scale_corrdinates(df_full)\n",
    "\n",
    "df_full = prepare_ml_dataset.scale_indexes(df_full)\n",
    "\n",
    "df_full = prepare_ml_dataset.scale_sw(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "129d61ae-9a62-47bc-a356-6752a6487352",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m feature_history_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m_feature\u001b[38;5;241m*\u001b[39mm_history)]\n\u001b[1;32m     12\u001b[0m index0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_history_total)\n\u001b[0;32m---> 13\u001b[0m index1 \u001b[38;5;241m=\u001b[39m df_full\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m df_history \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros((index1\u001b[38;5;241m-\u001b[39mindex0\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_history_names)))\n\u001b[1;32m     17\u001b[0m ihf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_full' is not defined"
     ]
    }
   ],
   "source": [
    "n_history_total_days = 7\n",
    "average_time = 300\n",
    "n_history_total = n_history_total_days*24*60*60/average_time\n",
    "m_history = int(n_history_total/24 + 1)\n",
    "history_resolution = 2*3600\n",
    "m_history = int(n_history_total/(history_resolution/average_time) + 1)\n",
    "feature_names=[ 'scaled_symh', 'scaled_ae','scaled_asyh', 'scaled_asyd']\n",
    "m_feature = len(feature_names)\n",
    "\n",
    "index_difference = history_resolution/average_time\n",
    "feature_history_names = [\"\" for x in range(m_feature*m_history)]\n",
    "index0 = int(n_history_total)\n",
    "index1 = df_full.index[-1]\n",
    "\n",
    "df_history = data=np.zeros((index1-index0+1, len(feature_history_names)))\n",
    "\n",
    "ihf=0\n",
    "for feature_name in feature_names:\n",
    "    for k in range(m_history):\n",
    "        name = feature_name + '_' + str(k*2)+'h'\n",
    "        feature_history_names[ihf] = name\n",
    "        temp = np.array(df_full.loc[(index0 - index_difference*k):(index1-index_difference*k), feature_name])\n",
    "        df_history[:,k] = temp\n",
    "        # df_full.loc[index0:index1,name] = np.array(df_full.loc[(index0 - index_difference*k):(index1-index_difference*k), feature_name])  \n",
    "        ihf = ihf + 1\n",
    "\n",
    "df_full.loc[index0:index1, feature_history_names] = df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb289f05-3f3b-434e-9361-c7b38f416138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b63536-eb9a-4724-8ad3-f8117cc5f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full, index_good, data_settings[\"feature_history_names\"] = prepare_ml_dataset.create_df_full('rel05', data_settings[\"y_name\"] , data_settings[\"y_name_log\"] ,  data_settings[\"feature_names\"] , data_settings[\"dL01\"] , data_settings[\"number_history\"] , data_settings[\"history_resolution\"] , data_settings[\"average_time\"], data_settings[\"forecast\"] , directories[\"data_dir\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e0e0c-e71b-478a-842a-efe15d0d6ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f4433-2c3e-4f91-a341-1c181250b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = np.empty((index1-index0+1, m_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d7f1-e9c2-4ca9-b384-a1eaf364d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test  = prepare_ml_dataset.load_csv_data(dataset_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4749c-3a96-480f-baad-8bccde97ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b729fc27-a98d-4da0-b74a-97840bac645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086963d-fdf7-4a11-9b7d-53e5d8f5e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, x_test, y_train, y_valid, y_test = prepare_ml_dataset.prepare_ml_dataset(energy, species)\n",
    "\n",
    "print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4522ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_name = \"learning_rate\"\n",
    "para_set = [1.e-4, 1.5e-3, 1.e-3]\n",
    "\n",
    "final_train_loss = np.zeros(len(para_set))\n",
    "final_valid_loss = np.zeros(len(para_set))\n",
    "total_history = dict()\n",
    "valid_r2s = np.zeros(len(para_set))\n",
    "\n",
    "for ipara in range(len(para_set)):\n",
    "    parameter = para_set[ipara]\n",
    "\n",
    "    model, history, valid_r2 = train_nn_model.nn_model(x_train, y_train, x_valid, y_valid, data_settings[\"y_name_log\"], \n",
    "                                                       output_dir = directories[\"training_output_dir\"] , n_neurons = 18, patience = 32,\n",
    "                                                       learning_rate = parameter, epochs = 10, batch_size = 8)\n",
    "    \n",
    "    total_history[str(parameter)] = history.history\n",
    "    final_train_loss[ipara] = history.history['loss'][-1]\n",
    "    final_valid_loss[ipara] = history.history['val_loss'][-1]\n",
    "    valid_r2s[ipara] = valid_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82defd-eb7a-4f44-9a78-87deaf96709b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
