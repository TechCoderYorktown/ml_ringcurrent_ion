{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55bc56-a326-4932-9fe8-c135fbe75c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import prepare_ml_dataset\n",
    "import importlib\n",
    "importlib.reload(prepare_ml_dataset)\n",
    "\n",
    "raw_feature_names =  ['symh','asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "\n",
    "# [51767.680, 44428.696, 38130.120, 32724.498, 28085.268, 24103.668, 20686.558, 17753.876, 15236.896, 13076.798, 11222.936, 9631.899, 8266.406, 7094.516, 6088.722, 5225.528, 4484.742\n",
    "# , 3848.919, 3303.284, 2834.964, 2433.055, 2088.129, 1792.096, 1538.062, 1319.977, 1132.846, 972.237]\n",
    "number_history_arr = [7,8]\n",
    "forecast_arr = [\"all\", \"index\",\"none\"]\n",
    "dL01_arr = [True, False]\n",
    "species_arr = ['h', 'o']\n",
    "energy_arr = ['972237', '51767680']  \n",
    "\n",
    "for number_history in number_history_arr:\n",
    "    for forecast in forecast_arr:\n",
    "       for dL01 in dL01_arr:\n",
    "           for species in species_arr:\n",
    "               for energy in energy_arr:\n",
    "               \n",
    "                    prepare_ml_dataset.prepare_ml_dataset(energy, species, recalc = True, plot_data = False, save_data = True\n",
    "                                                          , dL01=dL01, forecast = forecast, number_history =number_history, raw_feature_names =  raw_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9128d9a9-6d2a-42d1-94f8-e35eaf2f210e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 15:30:21.081785: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-25 15:30:21.082497: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 15:30:21.085350: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 15:30:21.091913: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742931021.102861  167423 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742931021.106165  167423 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 15:30:21.117701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'df_data' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m species \u001b[38;5;129;01min\u001b[39;00m species_arr:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m energy \u001b[38;5;129;01min\u001b[39;00m energy_arr:\n\u001b[0;32m---> 21\u001b[0m          prepare_ml_dataset\u001b[38;5;241m.\u001b[39mprepare_ml_dataset(energy, species, recalc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, plot_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, save_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m                                                , dL01\u001b[38;5;241m=\u001b[39mdL01, forecast \u001b[38;5;241m=\u001b[39m forecast, number_history \u001b[38;5;241m=\u001b[39mnumber_history, raw_feature_names \u001b[38;5;241m=\u001b[39m  raw_feature_names)\n",
      "File \u001b[0;32m~/workspace/GitHub/ml_ringcurrent_ion/prepare_ml_dataset.py:278\u001b[0m, in \u001b[0;36mprepare_ml_dataset\u001b[0;34m(energy, species, recalc, plot_data, save_data, dL01, average_time, raw_feature_names, forecast, number_history, test_ts, test_te)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart plot data\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_data:\n\u001b[0;32m--> 278\u001b[0m     plot_y_data(df_data\u001b[38;5;241m.\u001b[39mloc[index_good, [ fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m],  data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_y_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]]], data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_y_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],  fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m], fulldataset_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_y_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    280\u001b[0m     plot_coor_data(df_data\u001b[38;5;241m.\u001b[39mloc[index_good, [fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m],fulldata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoor_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]  ]], fulldata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoor_names\u001b[39m\u001b[38;5;124m\"\u001b[39m],  fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m], fulldataset_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_coor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    282\u001b[0m     plot_feature_data(df_data\u001b[38;5;241m.\u001b[39mloc[index_good, [fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m],fulldata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] ]], fulldata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names\u001b[39m\u001b[38;5;124m\"\u001b[39m],  fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_name\u001b[39m\u001b[38;5;124m'\u001b[39m], fulldataset_csv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_coor\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'df_data' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "# import prepare_ml_dataset\n",
    "# import importlib\n",
    "# importlib.reload(prepare_ml_dataset)\n",
    "\n",
    "# raw_feature_names =  ['symh','asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "\n",
    "# # [51767.680, 44428.696, 38130.120, 32724.498, 28085.268, 24103.668, 20686.558, 17753.876, 15236.896, 13076.798, 11222.936, 9631.899, 8266.406, 7094.516, 6088.722, 5225.528, 4484.742\n",
    "# # , 3848.919, 3303.284, 2834.964, 2433.055, 2088.129, 1792.096, 1538.062, 1319.977, 1132.846, 972.237]\n",
    "# number_history_arr = [7]\n",
    "# forecast_arr = [\"all\"]\n",
    "# dL01_arr = [True]\n",
    "# species_arr = ['h']\n",
    "# energy_arr = ['972237']  \n",
    "\n",
    "# for number_history in number_history_arr:\n",
    "#     for forecast in forecast_arr:\n",
    "#        for dL01 in dL01_arr:\n",
    "#            for species in species_arr:\n",
    "#                for energy in energy_arr:\n",
    "               \n",
    "#                     prepare_ml_dataset.prepare_ml_dataset(energy, species, recalc = True, plot_data = True, save_data = False\n",
    "#                                                           , dL01=dL01, forecast = forecast, number_history =number_history, raw_feature_names =  raw_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c708d919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_rel05/fulldata/df_hope_log_h_flux_972237\n",
      "start symh\n",
      "Reading from output_rel05/fulldata/df_feature_history_scaled_symh.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `DataFrame.__getitem__` for empty DataFrame is not currently supported by PandasOnDask, defaulting to pandas implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv data for probe a"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: Data type alias 'a' was deprecated in NumPy 2.0. Use the 'S' alias instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv data for probe b"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_good_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m df_data[[fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoubletime_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]] \u001b[38;5;241m=\u001b[39m df_full[[fulldata_settings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoubletime_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# df_data[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]] = df_full[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m index_good \u001b[38;5;241m=\u001b[39m get_good_index(df_full, data_settings, fulldata_settings)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecast\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     36\u001b[0m     data_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_history_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remove_features_by_time(fulldata_settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_history_names\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*_0h\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_good_index' is not defined"
     ]
    }
   ],
   "source": [
    "import prepare_fulldata\n",
    "import importlib\n",
    "import initialize_var\n",
    "import prepare_ml_dataset\n",
    "\n",
    "importlib.reload(prepare_fulldata)\n",
    "importlib.reload(prepare_ml_dataset)\n",
    "importlib.reload(initialize_var)\n",
    "\n",
    "recalc = False\n",
    "plot_data = True\n",
    "save_data = True\n",
    "\n",
    "raw_feature_names =  ['symh']#,'asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "number_history = 7\n",
    "energy = '972237'\n",
    "species = 'h'\n",
    "forecast = \"none\"\n",
    "dL01 = True\n",
    "test_ts = '2017-01-01'\n",
    "test_te = '2018-01-01'\n",
    "\n",
    "dataset_csv, data_settings, directories = initialize_var.initialize_data_var(energy=energy, species=species, raw_feature_names = raw_feature_names, forecast = forecast, number_history = number_history, test_ts=test_ts, test_te=test_te, dL01=dL01)\n",
    "        \n",
    "df_data, directories, fulldataset_csv, fulldata_settings = prepare_fulldata.load_fulldata(energy, species, recalc = recalc, raw_feature_names = raw_feature_names, number_history = number_history, save_data = save_data, plot_data = plot_data)\n",
    "        \n",
    "df_full = prepare_fulldata.read_probes_data(directories[\"rawdata_dir\"], fulldata_settings)\n",
    "\n",
    "df_data[[fulldata_settings['doubletime_name']]] = df_full[[fulldata_settings['doubletime_name']]]\n",
    "\n",
    "# df_data[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]] = df_full[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]]\n",
    "\n",
    "index_good = get_good_index(df_full, data_settings, fulldata_settings)\n",
    "\n",
    "if data_settings[\"forecast\"] == \"all\":\n",
    "    data_settings[\"feature_history_names\"] = remove_features_by_time(fulldata_settings[\"feature_history_names\"], \"*_0h\")\n",
    "elif data_settings[\"forecast\"] == \"index\":\n",
    "    data_settings[\"feature_history_names\"] = remove_index_features_by_time(fulldata_settings[\"feature_history_names\"], \"*_0h\")\n",
    "else:\n",
    "    data_settings[\"feature_history_names\"] = fulldata_settings[\"feature_history_names\"]            \n",
    "\n",
    "df_data = df_data.loc[index_good,[fulldata_settings['doubletime_name'], fulldata_settings['datetime_name'],data_settings['y_name'], data_settings['log_y_name']]+ fulldata_settings['coor_names']+fulldata_settings['feature_history_names']]\n",
    "\n",
    "df_full = df_full.loc[index_good, :]\n",
    "\n",
    "#set test set. Here we use one year (2017) of data for test set \n",
    "index_train, index_valid, index_test = create_ml_indexes(df_data,  fulldata_settings, data_settings[\"test_ts\"], data_settings[\"test_te\"])\n",
    "\n",
    "# Each round, one can only train one y. If train more than one y, need to  repeat from here\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = create_ml_data(df_data, index_train, index_valid, index_test, data_settings[\"log_y_name\"], fulldata_settings[\"coor_names\"], data_settings[\"feature_history_names\"])  \n",
    "\n",
    "print(\"shapes of x_train, x_valid, x_test, y_train, y_valid, y_test \")\n",
    "print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape)\n",
    "\n",
    "if save_data:\n",
    "    save_df_data(df_full.loc[index_good, [fulldata_settings['datetime_name'], data_settings[\"y_name\"]] + fulldata_settings[\"raw_coor_names\"] + fulldata_settings[\"raw_feature_names\"]], index_train, index_valid, index_test, dataset_csv)\n",
    "\n",
    "    save_csv_data(x_train, x_valid, x_test, y_train, y_valid, y_test , dataset_csv)\n",
    "    \n",
    "print(\"start plot data\") \n",
    "\n",
    "if plot_data:\n",
    "    plot_y_data(df_data.loc[index_good, [ fulldata_settings['datetime_name'],  data_settings[\"y_name\"],data_settings[\"log_y_name\"]]], data_settings[\"y_name\"],data_settings[\"log_y_name\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_y\"]+ data_settings[\"log_y_name\"])\n",
    "    \n",
    "    plot_coor_data(df_data.loc[index_good, [fulldata_settings['datetime_name'],fulldata_settings[\"coor_names\"]  ]], fulldata_settings[\"coor_names\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_coor\"])\n",
    "                \n",
    "    plot_feature_data(df_data.loc[index_good, [fulldata_settings['datetime_name'],fulldata_settings[\"feature_names\"] ]], fulldata_settings[\"feature_names\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_coor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5307e-d2e5-49be-9dd3-ea6563178ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60932f81-33fd-4143-b904-61b5b6390551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0f9f5-75bb-48ca-a38c-e009d8b1fee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36367560-d30e-41c5-a781-f56beec81e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0d37f-31fa-4d41-954b-9b711052c98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
