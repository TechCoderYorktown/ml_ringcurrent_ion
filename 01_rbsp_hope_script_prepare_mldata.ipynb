{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a14c9d-5af9-44b4-9482-4849942a97a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jliao/anaconda3/envs/notebook/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-25 17:16:23.602085: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-25 17:16:23.610744: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 17:16:23.688679: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-25 17:16:23.758703: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742937383.814938  183592 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742937383.831685  183592 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-25 17:16:23.971933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import prepare_ml_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b4bd1-548f-4045-ae70-21c9113e72dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here we run through calculate for all ml dataset as set in \n",
    "# import importlib\n",
    "# importlib.reload(prepare_ml_dataset)\n",
    "\n",
    "# prepare_ml_dataset.prepare_ml_dataset_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d55bc56-a326-4932-9fe8-c135fbe75c5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(prepare_ml_dataset)\n",
    "\n",
    "raw_feature_names =  ['symh','asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "\n",
    "# [51767.680, 44428.696, 38130.120, 32724.498, 28085.268, 24103.668, 20686.558, 17753.876, 15236.896, 13076.798, 11222.936, 9631.899, 8266.406, 7094.516, 6088.722, 5225.528, 4484.742\n",
    "# , 3848.919, 3303.284, 2834.964, 2433.055, 2088.129, 1792.096, 1538.062, 1319.977, 1132.846, 972.237]\n",
    "number_history_arr = [7,8]\n",
    "forecast_arr = [\"all\", \"index\",\"none\"]\n",
    "dL01_arr = [True, False]\n",
    "species_arr = ['h', 'o']\n",
    "energy_arr = ['972237', '51767680']  \n",
    "\n",
    "for number_history in number_history_arr:\n",
    "    for forecast in forecast_arr:\n",
    "       for dL01 in dL01_arr:\n",
    "           for species in species_arr:\n",
    "               for energy in energy_arr:\n",
    "               \n",
    "                    prepare_ml_dataset.load_ml_dataset(energy, species, recalc = True, plot_data = False, save_data = False\n",
    "                                                          , dL01=dL01, forecast = forecast, number_history =number_history, raw_feature_names =  raw_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128d9a9-6d2a-42d1-94f8-e35eaf2f210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import prepare_ml_dataset\n",
    "# import importlib\n",
    "# importlib.reload(prepare_ml_dataset)\n",
    "\n",
    "# raw_feature_names =  ['symh','asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "\n",
    "# # [51767.680, 44428.696, 38130.120, 32724.498, 28085.268, 24103.668, 20686.558, 17753.876, 15236.896, 13076.798, 11222.936, 9631.899, 8266.406, 7094.516, 6088.722, 5225.528, 4484.742\n",
    "# # , 3848.919, 3303.284, 2834.964, 2433.055, 2088.129, 1792.096, 1538.062, 1319.977, 1132.846, 972.237]\n",
    "# number_history_arr = [7]\n",
    "# forecast_arr = [\"all\"]\n",
    "# dL01_arr = [True]\n",
    "# species_arr = ['h']\n",
    "# energy_arr = ['972237']  \n",
    "\n",
    "# for number_history in number_history_arr:\n",
    "#     for forecast in forecast_arr:\n",
    "#        for dL01 in dL01_arr:\n",
    "#            for species in species_arr:\n",
    "#                for energy in energy_arr:\n",
    "               \n",
    "#                     prepare_ml_dataset.prepare_ml_dataset(energy, species, recalc = True, plot_data = True, save_data = False\n",
    "#                                                           , dL01=dL01, forecast = forecast, number_history =number_history, raw_feature_names =  raw_feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c708d919",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import prepare_fulldata\n",
    "import importlib\n",
    "import initialize_var\n",
    "import prepare_ml_dataset\n",
    "\n",
    "importlib.reload(prepare_fulldata)\n",
    "importlib.reload(prepare_ml_dataset)\n",
    "importlib.reload(initialize_var)\n",
    "\n",
    "recalc = False\n",
    "plot_data = True\n",
    "save_data = True\n",
    "\n",
    "raw_feature_names =  ['symh']#,'asyh','ae','asyd'] #['symh','asyh','asyd','ae','f10.7','kp','swp','swn','swv','by','bz']\n",
    "number_history = 7\n",
    "energy = '972237'\n",
    "species = 'h'\n",
    "forecast = \"none\"\n",
    "dL01 = True\n",
    "test_ts = '2017-01-01'\n",
    "test_te = '2018-01-01'\n",
    "\n",
    "dataset_csv, data_settings, directories = initialize_var.initialize_data_var(energy=energy, species=species, raw_feature_names = raw_feature_names, forecast = forecast, number_history = number_history, test_ts=test_ts, test_te=test_te, dL01=dL01)\n",
    "        \n",
    "df_data, directories, fulldataset_csv, fulldata_settings = prepare_fulldata.load_fulldata(energy, species, recalc = recalc, raw_feature_names = raw_feature_names, number_history = number_history, save_data = save_data, plot_data = plot_data)\n",
    "        \n",
    "df_full = prepare_fulldata.read_probes_data(directories[\"rawdata_dir\"], fulldata_settings)\n",
    "\n",
    "df_data[[fulldata_settings['doubletime_name']]] = df_full[[fulldata_settings['doubletime_name']]]\n",
    "\n",
    "# df_data[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]] = df_full[[fulldata_settings['doubletime_name']]+fulldata_settings[\"raw_coor_names\"]+ fulldata_settings[\"raw_feature_names\"]]\n",
    "\n",
    "index_good = get_good_index(df_full, data_settings, fulldata_settings)\n",
    "\n",
    "if data_settings[\"forecast\"] == \"all\":\n",
    "    data_settings[\"feature_history_names\"] = remove_features_by_time(fulldata_settings[\"feature_history_names\"], \"*_0h\")\n",
    "elif data_settings[\"forecast\"] == \"index\":\n",
    "    data_settings[\"feature_history_names\"] = remove_index_features_by_time(fulldata_settings[\"feature_history_names\"], \"*_0h\")\n",
    "else:\n",
    "    data_settings[\"feature_history_names\"] = fulldata_settings[\"feature_history_names\"]            \n",
    "\n",
    "df_data = df_data.loc[index_good,[fulldata_settings['doubletime_name'], fulldata_settings['datetime_name'],data_settings['y_name'], data_settings['log_y_name']]+ fulldata_settings['coor_names']+fulldata_settings['feature_history_names']]\n",
    "\n",
    "df_full = df_full.loc[index_good, :]\n",
    "\n",
    "#set test set. Here we use one year (2017) of data for test set \n",
    "index_train, index_valid, index_test = create_ml_indexes(df_data,  fulldata_settings, data_settings[\"test_ts\"], data_settings[\"test_te\"])\n",
    "\n",
    "# Each round, one can only train one y. If train more than one y, need to  repeat from here\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test = create_ml_data(df_data, index_train, index_valid, index_test, data_settings[\"log_y_name\"], fulldata_settings[\"coor_names\"], data_settings[\"feature_history_names\"])  \n",
    "\n",
    "print(\"shapes of x_train, x_valid, x_test, y_train, y_valid, y_test \")\n",
    "print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape, y_test.shape)\n",
    "\n",
    "if save_data:\n",
    "    save_df_data(df_full.loc[index_good, [fulldata_settings['datetime_name'], data_settings[\"y_name\"]] + fulldata_settings[\"raw_coor_names\"] + fulldata_settings[\"raw_feature_names\"]], index_train, index_valid, index_test, dataset_csv)\n",
    "\n",
    "    save_csv_data(x_train, x_valid, x_test, y_train, y_valid, y_test , dataset_csv)\n",
    "    \n",
    "if plot_data:\n",
    "    plot_y_data(df_data.loc[index_good, [ fulldata_settings['datetime_name'],  data_settings[\"y_name\"],data_settings[\"log_y_name\"]]], data_settings[\"y_name\"],data_settings[\"log_y_name\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_y\"]+ data_settings[\"log_y_name\"])\n",
    "    \n",
    "    plot_coor_data(df_data.loc[index_good, [fulldata_settings['datetime_name'],fulldata_settings[\"coor_names\"]  ]], fulldata_settings[\"coor_names\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_coor\"])\n",
    "                \n",
    "    plot_feature_data(df_data.loc[index_good, [fulldata_settings['datetime_name'],fulldata_settings[\"feature_names\"] ]], fulldata_settings[\"feature_names\"],  fulldata_settings['datetime_name'], fulldataset_csv[\"df_coor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c5307e-d2e5-49be-9dd3-ea6563178ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60932f81-33fd-4143-b904-61b5b6390551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0f9f5-75bb-48ca-a38c-e009d8b1fee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36367560-d30e-41c5-a781-f56beec81e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de0d37f-31fa-4d41-954b-9b711052c98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
